{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import mido\n",
    "from mido import Message, MetaMessage, MidiFile, MidiTrack\n",
    "import numpy\n",
    "import sklearn.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=numpy.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 1 + 8 + 8 + 16\n",
    "LOOKBACK = 128\n",
    "DEFAULT_TICKS = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(object): # technically not an autoencoder\n",
    "    def create(self, vocab_size=INPUT_WIDTH, max_length=LOOKBACK, latent_rep_size=128, lr=0.001):\n",
    "        self.encoder = None\n",
    "        self.predictor = None\n",
    "        #self.sentiment_predictor = None\n",
    "        self.autoencoder = None\n",
    "\n",
    "        x = Input(shape=(max_length, vocab_size))\n",
    "        #x_embed = Embedding(vocab_size, 64, input_length=max_length)(x)\n",
    "\n",
    "        vae_loss, encoded = self._build_encoder(x, latent_rep_size=latent_rep_size, max_length=max_length)\n",
    "        self.encoder = Model(inputs=x, outputs=encoded)\n",
    "\n",
    "        encoded_input = Input(shape=(latent_rep_size,))\n",
    "#         predicted_sentiment = self._build_sentiment_predictor(encoded_input)\n",
    "#         self.sentiment_predictor = Model(encoded_input, predicted_sentiment)\n",
    "\n",
    "        pred = self._build_predictor(encoded_input, vocab_size, max_length)\n",
    "        self.predictor = Model(encoded_input, pred)\n",
    "\n",
    "        self.autoencoder = Model(inputs=x, outputs=self._build_predictor(encoded, vocab_size, max_length))\n",
    "        self.autoencoder.compile(optimizer=Adam(lr=lr),\n",
    "                                 loss=vae_loss,\n",
    "                                 metrics=['accuracy'])\n",
    "    \n",
    "    def _build_encoder(self, x, latent_rep_size=128, max_length=None, epsilon_std=0.01):\n",
    "        h = Bidirectional(LSTM(500, return_sequences=True), merge_mode='concat')(x)\n",
    "        h = Dropout(0.5)(h)\n",
    "        h = Bidirectional(LSTM(500, return_sequences=False), merge_mode='concat')(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        h = Dense(435, activation='relu')(h)\n",
    "\n",
    "        def sampling(args):\n",
    "            z_mean_, z_log_var_ = args\n",
    "            batch_size = K.shape(z_mean_)[0]\n",
    "            epsilon = K.random_normal(shape=(batch_size, latent_rep_size), mean=0., stddev=epsilon_std)\n",
    "            return z_mean_ + K.exp(z_log_var_ / 2) * epsilon\n",
    "\n",
    "        z_mean = Dense(latent_rep_size, name='z_mean', activation='linear')(h)\n",
    "        z_log_var = Dense(latent_rep_size, name='z_log_var', activation='linear')(h)\n",
    "\n",
    "        def vae_loss(y, pred):\n",
    "            y = K.flatten(y)\n",
    "            pred = K.flatten(pred)\n",
    "            xent_loss = max_length * metrics.binary_crossentropy(y, pred)\n",
    "            kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "            return xent_loss + kl_loss\n",
    "\n",
    "        return (vae_loss, Lambda(sampling, output_shape=(latent_rep_size,), name='lambda')([z_mean, z_log_var]))\n",
    "    \n",
    "    def _build_predictor(self, encoded, vocab_size, max_length):\n",
    "        h = Dense(100, activation='relu')(encoded)\n",
    "        h = Dropout(0.25)(h)\n",
    "        h = Dense(50, activation='relu')(h)\n",
    "        pred = Dense(INPUT_WIDTH, activation='sigmoid', name='pred')(h)\n",
    "#         repeated_context = RepeatVector(max_length)(encoded)\n",
    "\n",
    "#         h = LSTM(500, return_sequences=True, name='dec_lstm_1')(repeated_context)\n",
    "#         #h = Dropout(0.5, name='dec_dropout_1')(h)\n",
    "#         h = LSTM(500, return_sequences=True, name='dec_lstm_2')(h)\n",
    "#         #h = Dropout(0.5, name='dec_dropout_2')(h)\n",
    "\n",
    "#         decoded = TimeDistributed(Dense(vocab_size, activation='sigmoid'), name='decoded_mean')(h)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "#     def _build_sentiment_predictor(self, encoded):\n",
    "#         h = Dense(100, activation='linear')(encoded)\n",
    "\n",
    "#         return Dense(INPUT_WIDTH, activation='sigmoid', name='pred')(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "model.create()\n",
    "model.autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midi(midi_file, track_name):\n",
    "    data = []\n",
    "    midi = mido.MidiFile(midi_file)\n",
    "    for track in midi.tracks:\n",
    "        if track.name == track_name:\n",
    "            for message in track:\n",
    "                if message.type in ['note_on', 'note_off']:\n",
    "                    data.append((1 if message.type == 'note_on' else 0, message.note, message.velocity, int(message.time * DEFAULT_TICKS / midi.ticks_per_beat)))\n",
    "    assert data\n",
    "    return numpy.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(data):\n",
    "    augmented = []\n",
    "    events = len(data)\n",
    "    maximum = data.max(axis=0)[1]\n",
    "    minimum = data.min(axis=0)[1]\n",
    "    transpositions = 128 - (maximum - minimum)\n",
    "    for i in range(transpositions):\n",
    "        sequence = numpy.copy(data)\n",
    "        for j in range(events):\n",
    "            sequence[j, 1] = data[j, 1] - minimum + i\n",
    "        augmented.append(sequence)\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "    encoded = []\n",
    "    for sequence in data:\n",
    "        encoded_sequence = numpy.zeros((len(sequence), INPUT_WIDTH), dtype=int)\n",
    "        for i, event in enumerate(sequence):\n",
    "            encoded_sequence[i, 0] = event[0]\n",
    "            encoded_sequence[i, 1:9] = [int(x) for x in format(event[1], '08b')]\n",
    "            encoded_sequence[i, 9:17] = [int(x) for x in format(event[2], '08b')]\n",
    "            encoded_sequence[i, 17:] = [int(x) for x in format(event[3], '016b')]\n",
    "        encoded.append(encoded_sequence)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(data):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sequence in data:\n",
    "        for i in range(len(sequence)):\n",
    "            if i == 0:\n",
    "                segment = numpy.zeros((1, INPUT_WIDTH), dtype=int)\n",
    "            else:\n",
    "                segment = sequence[max(i - LOOKBACK, 0):i, :]\n",
    "            if len(segment) < LOOKBACK:\n",
    "                pad = LOOKBACK - len(segment)\n",
    "                segment = numpy.pad(segment, [(pad, 0), (0, 0)], mode='constant')\n",
    "            #prepared.append((X, sequence[i, :]))\n",
    "            X.append(segment)\n",
    "            Y.append(sequence[i, :])\n",
    "    X = numpy.array(X)\n",
    "    Y = numpy.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(midi_dir, track_name):\n",
    "    X = []\n",
    "    Y = []\n",
    "    midi_files = sorted(glob.glob(os.path.join(midi_dir, '*.mid')) + glob.glob(os.path.join(midi_dir, '*.midi')))\n",
    "    for midi_file in midi_files:\n",
    "        try:\n",
    "            data = prepare(encode(augment(load_midi(midi_file, track_name))))\n",
    "            X.extend(data[0])\n",
    "            Y.extend(data[1])\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except:\n",
    "            print(\"Skipping\", midi_file)\n",
    "    #random.shuffle(all_data)\n",
    "    X = numpy.array(X)\n",
    "    Y = numpy.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_midi('/home/santiago/Projects/ProjectEuterpe/data/midi/1.mid', 'Chords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = augment(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = prepare(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dir = '/home/santiago/Projects/ProjectEuterpe/data/midi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_all(midi_dir, 'Chords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, Y, batch_size=32, shuffle=True, random_seed=0):\n",
    "    assert len(X) == len(Y)\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            X, Y = sklearn.utils.shuffle(X, Y, random_state=random_seed)\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            yield X[i:i + batch_size, :, :], Y[i:i + batch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator(data[0], data[1], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '/home/santiago/Projects/ProjectEuterpe/checkpoints/chords/vae_binary/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.autoencoder.load_weights('/home/santiago/Projects/ProjectEuterpe/checkpoints/chords/vae_binary/epoch90.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "while True:\n",
    "    epoch += 1\n",
    "    print('Epoch', epoch)\n",
    "    model.autoencoder.fit_generator(gen, math.ceil(len(data[0]) / BATCH_SIZE), epochs=1)\n",
    "    model.autoencoder.save_weights(os.path.join(checkpoint_dir, 'epoch{}.hdf5'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bits_to_int(bits):\n",
    "    out = 0\n",
    "    for bit in bits:\n",
    "        out = (out << 1) | bit\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_midi(data, note_offset=0):\n",
    "    midi = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi.tracks.append(track)\n",
    "    #track.append(MetaMessage('set_tempo', tempo=500000, time=0))\n",
    "    for event in data:\n",
    "        onoff = 'note_on' if event[0] == 1 else 'note_off'\n",
    "        note = bits_to_int(event[1:9]) + note_offset\n",
    "        velocity = bits_to_int(event[9:17])\n",
    "        time = bits_to_int(event[17:])\n",
    "        track.append(Message(onoff, note=note, velocity=velocity, time=time))\n",
    "    return midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = numpy.zeros((1, LOOKBACK, INPUT_WIDTH), dtype=int)\n",
    "#history = numpy.random.randint(2, size=(1, LOOKBACK, INPUT_WIDTH), dtype=int)\n",
    "for i in range(400):\n",
    "    history = numpy.concatenate([history, numpy.round(model.autoencoder.predict(history[:, -LOOKBACK:, :])).astype(int)[:, numpy.newaxis, :]], axis=1)\n",
    "history = history[0, LOOKBACK:, :]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = to_midi(history, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(midi.tracks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi.save('/home/santiago/Projects/ProjectEuterpe/data/test/test_vae_binary15.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
