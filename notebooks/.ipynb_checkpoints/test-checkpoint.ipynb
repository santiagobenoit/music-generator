{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "import mido\n",
    "import numpy\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = 36\n",
    "lookback = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_vector = Input((None, notes))\n",
    "# input_layer = TimeDistributed(Dense(notes, activation='sigmoid'))(input_vector)\n",
    "# previous_layer = input_layer\n",
    "# for units in reversed(range(notes // 6, notes + 1, 4)):\n",
    "#     hidden_layer = Bidirectional(LSTM(units, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(previous_layer)\n",
    "#     previous_layer = hidden_layer\n",
    "# middle_layer = TimeDistributed(Dense(notes // 6, activation='sigmoid'))(previous_layer)\n",
    "# previous_layer = middle_layer\n",
    "# for units in range(notes // 6, notes + 1, 4):\n",
    "#     hidden_layer = Bidirectional(LSTM(units, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(previous_layer)\n",
    "#     previous_layer = hidden_layer\n",
    "# output_layer = TimeDistributed(Dense(notes, activation='sigmoid'))(previous_layer)\n",
    "# model = Model(input_vector, output_layer)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 + notes + 8 + 16\n",
    "input_layer = Input((None, input_size))\n",
    "previous_layer = input_layer\n",
    "for units in reversed(range(input_size // 6, input_size + 1, 8)):\n",
    "    hidden_layer = Bidirectional(LSTM(units, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(previous_layer)\n",
    "    previous_layer = hidden_layer\n",
    "middle_layer = TimeDistributed(Activation('sigmoid'))(previous_layer)\n",
    "previous_layer = middle_layer\n",
    "for units in range(input_size // 6, input_size + 1, 8):\n",
    "    hidden_layer = Bidirectional(LSTM(units, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(previous_layer)\n",
    "    previous_layer = hidden_layer\n",
    "output_layer = TimeDistributed(Dense(input_size, activation='sigmoid'))(previous_layer)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.zeros((1, 16, 57), dtype=int)\n",
    "for i in range(16):\n",
    "    x[:, i, i:i+4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = numpy.invert(numpy.roll(x, -1, axis=1)) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.round(model.predict(x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = mido.MidiFile('/home/santiago/Projects/MusicGenerator/data/midi/6.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for track in midi.tracks:\n",
    "    if track.name == 'Melody':\n",
    "        for message in track:\n",
    "            test.append(message)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chords_from_midi(midi_file):\n",
    "    data = []\n",
    "    midi = mido.MidiFile(midi_file)\n",
    "    for track in midi.tracks:\n",
    "        if track.name == 'Chords':\n",
    "            for message in track:\n",
    "                if message.type in ['note_on', 'note_off']:\n",
    "                    data.append((1 if message.type == 'note_on' else 0, message.note, message.velocity, message.time))\n",
    "    return numpy.array(data)\n",
    "\n",
    "\n",
    "def encode_chords(chords):\n",
    "    data = []\n",
    "    minimum = min(chords[:, 1])\n",
    "    prev_type = None\n",
    "    prev_veloc = None\n",
    "    encoded = None\n",
    "    for chord in chords:\n",
    "        if prev_type != chord[0] or prev_veloc != chord[2] or chord[3] != 0:\n",
    "            if encoded is not None:\n",
    "                data.append(encoded)\n",
    "            encoded = numpy.zeros((1 + notes + 8 + 16,))\n",
    "            encoded[0] = chord[0]\n",
    "            encoded[1 + notes:1 + notes + 8] = [int(x) for x in format(chord[2], '08b')]\n",
    "            encoded[1 + notes + 8:1 + notes + 8 + 16] = [int(x) for x in format(chord[3], '016b')]\n",
    "        encoded[1 + chord[1] - minimum] = 1\n",
    "        prev_type = chord[0]\n",
    "        prev_veloc = chord[2]\n",
    "    return numpy.array(data)\n",
    "\n",
    "\n",
    "def load_chords(midi_dir):\n",
    "    progressions = []\n",
    "    midi_files = sorted(glob.glob(os.path.join(midi_dir, '*.mid')) + glob.glob(os.path.join(midi_dir, '*.midi')))\n",
    "    for midi_file in midi_files:\n",
    "        try:\n",
    "            chords = chords_from_midi(midi_file)\n",
    "            encoded = encode_chords(chords)\n",
    "            progressions.append(encoded)\n",
    "        except (KeyboardInterrupt, SystemExit):\n",
    "            raise\n",
    "        except:\n",
    "            print(\"Skipping\", midi_file)\n",
    "    return progressions\n",
    "\n",
    "def input_output(sequence):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(sequence)):\n",
    "        if i == 0:\n",
    "            x.append(numpy.zeros((1, 1, 1 + notes + 8 + 16)).astype(int))\n",
    "        else:\n",
    "            x.append(numpy.vstack([numpy.zeros((1, 1 + notes + 8 + 16)), sequence[:i, :]])[numpy.newaxis, :, :].astype(int))\n",
    "            #x.append(sequence[numpy.newaxis, :i, :])\n",
    "        y.append(sequence[numpy.newaxis, i, :].astype(int))\n",
    "    return (x, y)\n",
    "\n",
    "def generator(data):\n",
    "    assert len(data[0]) == len(data[1])\n",
    "    while True:\n",
    "        for i in range(len(data[0])):\n",
    "            yield (data[0][i], data[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = chords_from_midi('/home/santiago/Projects/MusicGenerator/data/midi/6.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encode_chords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in x:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = input_output(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 1 + notes + 8 + 16\n",
    "# input_layer = Input((None, input_size))\n",
    "# x = Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(input_layer)\n",
    "# x = Conv1D(128, 3, padding='causal')(x)\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(x)\n",
    "# x = Conv1D(32, 3, padding='causal')(x)\n",
    "# x = Bidirectional(LSTM(16, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(x)\n",
    "# x = Conv1D(16, 3, padding='causal')(x)\n",
    "# middle_layer = TimeDistributed(Activation('sigmoid'))(x)\n",
    "# x = Conv1D(32, 3, padding='causal')(middle_layer)\n",
    "# x = Bidirectional(LSTM(32, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True, recurrent_dropout=0.5), merge_mode='concat')(x)\n",
    "# output_layer = TimeDistributed(Dense(input_size, activation='sigmoid'))(x)\n",
    "# model = Model(input_layer, output_layer)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 + notes + 8 + 16\n",
    "input_layer = Input((256, input_size))\n",
    "x = Bidirectional(LSTM(256, recurrent_dropout=0.5, return_sequences=True), merge_mode='concat')(input_layer)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = MaxPool1D(2)(x)\n",
    "# x = Conv1D(64, 3, padding='causal')(x)\n",
    "# x = Flatten()(x)\n",
    "x = Bidirectional(LSTM(256, recurrent_dropout=0.5), merge_mode='concat')(input_layer)\n",
    "output_layer = Dense(input_size, activation='sigmoid')(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator(train_data), 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = numpy.round(model.predict(X[numpy.newaxis, :, :])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:, :, 1:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1 + notes + 8 + 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, None, 61)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, None, 256)         194560    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, None, 16, 16, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_17 (ConvLSTM2D) (None, None, 16, 16, 1)   76        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, None, 16, 16, 1)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, None, 8, 8, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_18 (ConvLSTM2D) (None, 6, 6, 1)           76        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 6, 6, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 61)                2257      \n",
      "=================================================================\n",
      "Total params: 196,969\n",
      "Trainable params: 196,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((None, input_size))\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = TimeDistributed(Reshape((16, 16, 1)))(x)\n",
    "x = ConvLSTM2D(1, (3, 3), padding='same', return_sequences=True)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = TimeDistributed(MaxPool2D(2))(x)\n",
    "x = ConvLSTM2D(1, (3, 3), return_sequences=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Flatten()(x)\n",
    "output_layer = Dense(input_size, activation='sigmoid')(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "128/128 [==============================] - 6s - loss: 0.1510 - acc: 0.9306     \n",
      "Epoch 2/128\n",
      "128/128 [==============================] - 6s - loss: 0.1497 - acc: 0.9315     \n",
      "Epoch 3/128\n",
      "128/128 [==============================] - 6s - loss: 0.1488 - acc: 0.9315     \n",
      "Epoch 4/128\n",
      "128/128 [==============================] - 6s - loss: 0.1475 - acc: 0.9322     \n",
      "Epoch 5/128\n",
      "128/128 [==============================] - 6s - loss: 0.1459 - acc: 0.9360     \n",
      "Epoch 6/128\n",
      "128/128 [==============================] - 6s - loss: 0.1442 - acc: 0.9389     \n",
      "Epoch 7/128\n",
      "128/128 [==============================] - 6s - loss: 0.1436 - acc: 0.9398     \n",
      "Epoch 8/128\n",
      "128/128 [==============================] - 6s - loss: 0.1425 - acc: 0.9390     \n",
      "Epoch 9/128\n",
      "128/128 [==============================] - 6s - loss: 0.1417 - acc: 0.9399     \n",
      "Epoch 10/128\n",
      "128/128 [==============================] - 6s - loss: 0.1408 - acc: 0.9419     \n",
      "Epoch 11/128\n",
      "128/128 [==============================] - 6s - loss: 0.1385 - acc: 0.9444     \n",
      "Epoch 12/128\n",
      "128/128 [==============================] - 6s - loss: 0.1383 - acc: 0.9433     \n",
      "Epoch 13/128\n",
      "128/128 [==============================] - 6s - loss: 0.1372 - acc: 0.9431     \n",
      "Epoch 14/128\n",
      "128/128 [==============================] - 6s - loss: 0.1364 - acc: 0.9447     \n",
      "Epoch 15/128\n",
      "128/128 [==============================] - 6s - loss: 0.1355 - acc: 0.9454     \n",
      "Epoch 16/128\n",
      "128/128 [==============================] - 6s - loss: 0.1346 - acc: 0.9460     \n",
      "Epoch 17/128\n",
      "128/128 [==============================] - 6s - loss: 0.1328 - acc: 0.9468     \n",
      "Epoch 18/128\n",
      "128/128 [==============================] - 6s - loss: 0.1324 - acc: 0.9474     \n",
      "Epoch 19/128\n",
      "128/128 [==============================] - 6s - loss: 0.1309 - acc: 0.9474     \n",
      "Epoch 20/128\n",
      "128/128 [==============================] - 6s - loss: 0.1306 - acc: 0.9475     \n",
      "Epoch 21/128\n",
      "128/128 [==============================] - 6s - loss: 0.1299 - acc: 0.9480     \n",
      "Epoch 22/128\n",
      "128/128 [==============================] - 6s - loss: 0.1275 - acc: 0.9508     \n",
      "Epoch 23/128\n",
      "128/128 [==============================] - 6s - loss: 0.1278 - acc: 0.9511     \n",
      "Epoch 24/128\n",
      "128/128 [==============================] - 6s - loss: 0.1264 - acc: 0.9515     \n",
      "Epoch 25/128\n",
      "128/128 [==============================] - 6s - loss: 0.1263 - acc: 0.9525     \n",
      "Epoch 26/128\n",
      "128/128 [==============================] - 6s - loss: 0.1251 - acc: 0.9538     \n",
      "Epoch 27/128\n",
      "128/128 [==============================] - 6s - loss: 0.1236 - acc: 0.9550     \n",
      "Epoch 28/128\n",
      "128/128 [==============================] - 6s - loss: 0.1226 - acc: 0.9553     \n",
      "Epoch 29/128\n",
      "128/128 [==============================] - 6s - loss: 0.1221 - acc: 0.9552     \n",
      "Epoch 30/128\n",
      "128/128 [==============================] - 6s - loss: 0.1210 - acc: 0.9549     \n",
      "Epoch 31/128\n",
      "128/128 [==============================] - 6s - loss: 0.1209 - acc: 0.9541     \n",
      "Epoch 32/128\n",
      "128/128 [==============================] - 6s - loss: 0.1194 - acc: 0.9562     \n",
      "Epoch 33/128\n",
      "128/128 [==============================] - 6s - loss: 0.1173 - acc: 0.9572     \n",
      "Epoch 34/128\n",
      "128/128 [==============================] - 6s - loss: 0.1174 - acc: 0.9559     \n",
      "Epoch 35/128\n",
      "128/128 [==============================] - 6s - loss: 0.1165 - acc: 0.9556     \n",
      "Epoch 36/128\n",
      "128/128 [==============================] - 6s - loss: 0.1161 - acc: 0.9570     \n",
      "Epoch 37/128\n",
      "128/128 [==============================] - 6s - loss: 0.1147 - acc: 0.9568     \n",
      "Epoch 38/128\n",
      "128/128 [==============================] - 6s - loss: 0.1136 - acc: 0.9567     \n",
      "Epoch 39/128\n",
      "128/128 [==============================] - 6s - loss: 0.1123 - acc: 0.9577     \n",
      "Epoch 40/128\n",
      "128/128 [==============================] - 6s - loss: 0.1120 - acc: 0.9575     \n",
      "Epoch 41/128\n",
      "128/128 [==============================] - 6s - loss: 0.1111 - acc: 0.9576     \n",
      "Epoch 42/128\n",
      "128/128 [==============================] - 6s - loss: 0.1106 - acc: 0.9563     \n",
      "Epoch 43/128\n",
      "128/128 [==============================] - 6s - loss: 0.1090 - acc: 0.9576     \n",
      "Epoch 44/128\n",
      "128/128 [==============================] - 6s - loss: 0.1075 - acc: 0.9586     \n",
      "Epoch 45/128\n",
      "128/128 [==============================] - 6s - loss: 0.1074 - acc: 0.9579     \n",
      "Epoch 46/128\n",
      "128/128 [==============================] - 6s - loss: 0.1059 - acc: 0.9586     \n",
      "Epoch 47/128\n",
      "128/128 [==============================] - 6s - loss: 0.1050 - acc: 0.9603     \n",
      "Epoch 48/128\n",
      "128/128 [==============================] - 6s - loss: 0.1044 - acc: 0.9593     \n",
      "Epoch 49/128\n",
      "128/128 [==============================] - 6s - loss: 0.1040 - acc: 0.9598     \n",
      "Epoch 50/128\n",
      "128/128 [==============================] - 6s - loss: 0.1022 - acc: 0.9607     \n",
      "Epoch 51/128\n",
      "128/128 [==============================] - 6s - loss: 0.1022 - acc: 0.9604     \n",
      "Epoch 52/128\n",
      "128/128 [==============================] - 6s - loss: 0.1008 - acc: 0.9609     \n",
      "Epoch 53/128\n",
      "128/128 [==============================] - 6s - loss: 0.1006 - acc: 0.9613     \n",
      "Epoch 54/128\n",
      "128/128 [==============================] - 6s - loss: 0.0993 - acc: 0.9629     \n",
      "Epoch 55/128\n",
      "128/128 [==============================] - 6s - loss: 0.0979 - acc: 0.9629     \n",
      "Epoch 56/128\n",
      "128/128 [==============================] - 6s - loss: 0.0979 - acc: 0.9626     \n",
      "Epoch 57/128\n",
      "128/128 [==============================] - 6s - loss: 0.0974 - acc: 0.9612     \n",
      "Epoch 58/128\n",
      "128/128 [==============================] - 6s - loss: 0.0962 - acc: 0.9647     \n",
      "Epoch 59/128\n",
      "128/128 [==============================] - 6s - loss: 0.0955 - acc: 0.9653     \n",
      "Epoch 60/128\n",
      "128/128 [==============================] - 6s - loss: 0.0948 - acc: 0.9643     \n",
      "Epoch 61/128\n",
      "128/128 [==============================] - 6s - loss: 0.0933 - acc: 0.9672     \n",
      "Epoch 62/128\n",
      "128/128 [==============================] - 6s - loss: 0.0931 - acc: 0.9687     \n",
      "Epoch 63/128\n",
      "128/128 [==============================] - 6s - loss: 0.0927 - acc: 0.9677     \n",
      "Epoch 64/128\n",
      "128/128 [==============================] - 6s - loss: 0.0931 - acc: 0.9670     \n",
      "Epoch 65/128\n",
      "128/128 [==============================] - 6s - loss: 0.0913 - acc: 0.9707     \n",
      "Epoch 66/128\n",
      "128/128 [==============================] - 6s - loss: 0.0903 - acc: 0.9695     \n",
      "Epoch 67/128\n",
      "128/128 [==============================] - 6s - loss: 0.0905 - acc: 0.9702     \n",
      "Epoch 68/128\n",
      "128/128 [==============================] - 6s - loss: 0.0894 - acc: 0.9707     \n",
      "Epoch 69/128\n",
      "128/128 [==============================] - 6s - loss: 0.0885 - acc: 0.9705     \n",
      "Epoch 70/128\n",
      "128/128 [==============================] - 6s - loss: 0.0880 - acc: 0.9725     \n",
      "Epoch 71/128\n",
      "128/128 [==============================] - 6s - loss: 0.0875 - acc: 0.9725     \n",
      "Epoch 72/128\n",
      "128/128 [==============================] - 6s - loss: 0.0859 - acc: 0.9726     \n",
      "Epoch 73/128\n",
      "128/128 [==============================] - 6s - loss: 0.0862 - acc: 0.9730     \n",
      "Epoch 74/128\n",
      "128/128 [==============================] - 6s - loss: 0.0853 - acc: 0.9735     \n",
      "Epoch 75/128\n",
      "128/128 [==============================] - 6s - loss: 0.0851 - acc: 0.9736     \n",
      "Epoch 76/128\n",
      "128/128 [==============================] - 6s - loss: 0.0839 - acc: 0.9750     \n",
      "Epoch 77/128\n",
      "128/128 [==============================] - 6s - loss: 0.0829 - acc: 0.9736     \n",
      "Epoch 78/128\n",
      "128/128 [==============================] - 6s - loss: 0.0830 - acc: 0.9743     \n",
      "Epoch 79/128\n",
      "128/128 [==============================] - 6s - loss: 0.0827 - acc: 0.9730     \n",
      "Epoch 80/128\n",
      "128/128 [==============================] - 6s - loss: 0.0816 - acc: 0.9750     \n",
      "Epoch 81/128\n",
      "128/128 [==============================] - 6s - loss: 0.0809 - acc: 0.9762     \n",
      "Epoch 82/128\n",
      "128/128 [==============================] - 6s - loss: 0.0807 - acc: 0.9763     \n",
      "Epoch 83/128\n",
      "128/128 [==============================] - 6s - loss: 0.0796 - acc: 0.9768     \n",
      "Epoch 84/128\n",
      "128/128 [==============================] - 6s - loss: 0.0797 - acc: 0.9784     \n",
      "Epoch 85/128\n",
      "128/128 [==============================] - 6s - loss: 0.0789 - acc: 0.9781     \n",
      "Epoch 86/128\n",
      "128/128 [==============================] - 6s - loss: 0.0787 - acc: 0.9780     \n",
      "Epoch 87/128\n",
      "128/128 [==============================] - 6s - loss: 0.0771 - acc: 0.9793     \n",
      "Epoch 88/128\n",
      "128/128 [==============================] - 6s - loss: 0.0765 - acc: 0.9784     \n",
      "Epoch 89/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 6s - loss: 0.0769 - acc: 0.9790     - ETA: \n",
      "Epoch 90/128\n",
      "128/128 [==============================] - 6s - loss: 0.0763 - acc: 0.9781     \n",
      "Epoch 91/128\n",
      "128/128 [==============================] - 6s - loss: 0.0755 - acc: 0.9791     \n",
      "Epoch 92/128\n",
      "128/128 [==============================] - 6s - loss: 0.0749 - acc: 0.9800     \n",
      "Epoch 93/128\n",
      "128/128 [==============================] - 6s - loss: 0.0747 - acc: 0.9808     \n",
      "Epoch 94/128\n",
      "128/128 [==============================] - 6s - loss: 0.0738 - acc: 0.9812     \n",
      "Epoch 95/128\n",
      "128/128 [==============================] - 6s - loss: 0.0734 - acc: 0.9817     \n",
      "Epoch 96/128\n",
      "128/128 [==============================] - 6s - loss: 0.0735 - acc: 0.9804     \n",
      "Epoch 97/128\n",
      "128/128 [==============================] - 6s - loss: 0.0726 - acc: 0.9818     \n",
      "Epoch 98/128\n",
      "128/128 [==============================] - 6s - loss: 0.0714 - acc: 0.9825     \n",
      "Epoch 99/128\n",
      "128/128 [==============================] - 6s - loss: 0.0707 - acc: 0.9822     \n",
      "Epoch 100/128\n",
      "128/128 [==============================] - 6s - loss: 0.0707 - acc: 0.9827     \n",
      "Epoch 101/128\n",
      "128/128 [==============================] - 6s - loss: 0.0695 - acc: 0.9830     \n",
      "Epoch 102/128\n",
      "128/128 [==============================] - 6s - loss: 0.0696 - acc: 0.9832     \n",
      "Epoch 103/128\n",
      "128/128 [==============================] - 6s - loss: 0.0689 - acc: 0.9837     \n",
      "Epoch 104/128\n",
      "128/128 [==============================] - 6s - loss: 0.0677 - acc: 0.9853     \n",
      "Epoch 105/128\n",
      "128/128 [==============================] - 6s - loss: 0.0665 - acc: 0.9855     \n",
      "Epoch 106/128\n",
      "128/128 [==============================] - 6s - loss: 0.0668 - acc: 0.9862     \n",
      "Epoch 107/128\n",
      "128/128 [==============================] - 6s - loss: 0.0674 - acc: 0.9855     \n",
      "Epoch 108/128\n",
      "128/128 [==============================] - 6s - loss: 0.0652 - acc: 0.9869     \n",
      "Epoch 109/128\n",
      "128/128 [==============================] - 6s - loss: 0.0645 - acc: 0.9872     \n",
      "Epoch 110/128\n",
      "128/128 [==============================] - 6s - loss: 0.0634 - acc: 0.9877     \n",
      "Epoch 111/128\n",
      "128/128 [==============================] - 6s - loss: 0.0641 - acc: 0.9848     \n",
      "Epoch 112/128\n",
      "128/128 [==============================] - 6s - loss: 0.0633 - acc: 0.9868     \n",
      "Epoch 113/128\n",
      "128/128 [==============================] - 6s - loss: 0.0624 - acc: 0.9872     \n",
      "Epoch 114/128\n",
      "128/128 [==============================] - 6s - loss: 0.0624 - acc: 0.9894     \n",
      "Epoch 115/128\n",
      "128/128 [==============================] - 6s - loss: 0.0617 - acc: 0.9890     \n",
      "Epoch 116/128\n",
      "128/128 [==============================] - 6s - loss: 0.0602 - acc: 0.9898     \n",
      "Epoch 117/128\n",
      "128/128 [==============================] - 6s - loss: 0.0602 - acc: 0.9901     \n",
      "Epoch 118/128\n",
      "128/128 [==============================] - 6s - loss: 0.0600 - acc: 0.9901     \n",
      "Epoch 119/128\n",
      "128/128 [==============================] - 6s - loss: 0.0596 - acc: 0.9899     \n",
      "Epoch 120/128\n",
      "128/128 [==============================] - 6s - loss: 0.0585 - acc: 0.9908     \n",
      "Epoch 121/128\n",
      "128/128 [==============================] - 6s - loss: 0.0576 - acc: 0.9909     \n",
      "Epoch 122/128\n",
      "128/128 [==============================] - 6s - loss: 0.0583 - acc: 0.9913     \n",
      "Epoch 123/128\n",
      "128/128 [==============================] - 6s - loss: 0.0571 - acc: 0.9913     \n",
      "Epoch 124/128\n",
      "128/128 [==============================] - 6s - loss: 0.0568 - acc: 0.9912     \n",
      "Epoch 125/128\n",
      "128/128 [==============================] - 6s - loss: 0.0564 - acc: 0.9917     \n",
      "Epoch 126/128\n",
      "128/128 [==============================] - 6s - loss: 0.0559 - acc: 0.9910     \n",
      "Epoch 127/128\n",
      "128/128 [==============================] - 6s - loss: 0.0552 - acc: 0.9910     \n",
      "Epoch 128/128\n",
      "128/128 [==============================] - 6s - loss: 0.0547 - acc: 0.9918     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15fa1339b0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator(train_data), 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.round(model.predict(train_data[0][0])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, None, 61)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, None, 256)         194560    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, None, 16, 16, 1)   0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_22 (ConvLSTM2D) (None, None, 16, 16, 1)   76        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, None, 16, 16, 1)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, None, 8, 8, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_23 (ConvLSTM2D) (None, 6, 6, 1)           76        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 6, 6, 1)           0         \n",
      "=================================================================\n",
      "Total params: 194,712\n",
      "Trainable params: 194,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer2 = Input((None, input_size))\n",
    "x2 = Bidirectional(LSTM(128, return_sequences=True, weights=model.layers[1].get_weights()))(input_layer2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = TimeDistributed(Reshape((16, 16, 1)))(x2)\n",
    "x2 = ConvLSTM2D(1, (3, 3), padding='same', return_sequences=True, weights=model.layers[4].get_weights())(x2)\n",
    "x2 = Activation('relu')(x2)\n",
    "x2 = TimeDistributed(MaxPool2D(2))(x2)\n",
    "x2 = ConvLSTM2D(1, (3, 3), return_sequences=False, weights=model.layers[7].get_weights())(x2)\n",
    "output_layer2 = Activation('relu')(x2)\n",
    "model2 = Model(input_layer2, output_layer2)\n",
    "model2.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f15f846c2b0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEYCAYAAABfgk2GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCEuXjLUPQUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15f84a05c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skimage.io.imshow(model2.predict(train_data[0][21]).reshape((3, 4, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, None, 61)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, None, 256)         194560    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_24 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 61)                15677     \n",
      "=================================================================\n",
      "Total params: 604,477\n",
      "Trainable params: 604,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((None, input_size))\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(128, return_sequences=False))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(input_size, activation='sigmoid')(x)\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "128/128 [==============================] - 5s - loss: 0.5602 - acc: 0.7770     \n",
      "Epoch 2/128\n",
      "128/128 [==============================] - 4s - loss: 0.3478 - acc: 0.8537     \n",
      "Epoch 3/128\n",
      "128/128 [==============================] - 4s - loss: 0.3012 - acc: 0.8600     \n",
      "Epoch 4/128\n",
      "128/128 [==============================] - 4s - loss: 0.2919 - acc: 0.8592     \n",
      "Epoch 5/128\n",
      "128/128 [==============================] - 4s - loss: 0.2800 - acc: 0.8618     \n",
      "Epoch 6/128\n",
      "128/128 [==============================] - 4s - loss: 0.2698 - acc: 0.8609     \n",
      "Epoch 7/128\n",
      "128/128 [==============================] - 4s - loss: 0.2715 - acc: 0.8627     \n",
      "Epoch 8/128\n",
      "128/128 [==============================] - 4s - loss: 0.2675 - acc: 0.8600     \n",
      "Epoch 9/128\n",
      "128/128 [==============================] - 4s - loss: 0.2665 - acc: 0.8630     \n",
      "Epoch 10/128\n",
      "128/128 [==============================] - 4s - loss: 0.2621 - acc: 0.8626     \n",
      "Epoch 11/128\n",
      "128/128 [==============================] - 4s - loss: 0.2545 - acc: 0.8657     \n",
      "Epoch 12/128\n",
      "128/128 [==============================] - 4s - loss: 0.2548 - acc: 0.8689     \n",
      "Epoch 13/128\n",
      "128/128 [==============================] - 4s - loss: 0.2493 - acc: 0.8718     \n",
      "Epoch 14/128\n",
      "128/128 [==============================] - 4s - loss: 0.2523 - acc: 0.8683     \n",
      "Epoch 15/128\n",
      "128/128 [==============================] - 4s - loss: 0.2451 - acc: 0.8755     \n",
      "Epoch 16/128\n",
      "128/128 [==============================] - 4s - loss: 0.2399 - acc: 0.8772     \n",
      "Epoch 17/128\n",
      "128/128 [==============================] - 4s - loss: 0.2322 - acc: 0.8813     \n",
      "Epoch 18/128\n",
      "128/128 [==============================] - 4s - loss: 0.2252 - acc: 0.8900     \n",
      "Epoch 19/128\n",
      "128/128 [==============================] - 4s - loss: 0.2062 - acc: 0.9028     \n",
      "Epoch 20/128\n",
      "128/128 [==============================] - 4s - loss: 0.1998 - acc: 0.9119     \n",
      "Epoch 21/128\n",
      "128/128 [==============================] - 4s - loss: 0.2052 - acc: 0.9093     \n",
      "Epoch 22/128\n",
      "128/128 [==============================] - 4s - loss: 0.1774 - acc: 0.9276     \n",
      "Epoch 23/128\n",
      "128/128 [==============================] - 4s - loss: 0.1612 - acc: 0.9420     \n",
      "Epoch 24/128\n",
      "128/128 [==============================] - 4s - loss: 0.1401 - acc: 0.9545     \n",
      "Epoch 25/128\n",
      "128/128 [==============================] - 4s - loss: 0.1238 - acc: 0.9640     \n",
      "Epoch 26/128\n",
      "128/128 [==============================] - 4s - loss: 0.1160 - acc: 0.9634     \n",
      "Epoch 27/128\n",
      "128/128 [==============================] - 4s - loss: 0.1069 - acc: 0.9684     \n",
      "Epoch 28/128\n",
      "128/128 [==============================] - 4s - loss: 0.0952 - acc: 0.9721     \n",
      "Epoch 29/128\n",
      "128/128 [==============================] - 4s - loss: 0.0916 - acc: 0.9740     \n",
      "Epoch 30/128\n",
      "128/128 [==============================] - 4s - loss: 0.0852 - acc: 0.9776     \n",
      "Epoch 31/128\n",
      "128/128 [==============================] - 4s - loss: 0.0764 - acc: 0.9830     \n",
      "Epoch 32/128\n",
      "128/128 [==============================] - 4s - loss: 0.0718 - acc: 0.9840     \n",
      "Epoch 33/128\n",
      "128/128 [==============================] - 4s - loss: 0.0600 - acc: 0.9882     \n",
      "Epoch 34/128\n",
      "128/128 [==============================] - 4s - loss: 0.0608 - acc: 0.9882     \n",
      "Epoch 35/128\n",
      "128/128 [==============================] - 4s - loss: 0.0566 - acc: 0.9891     \n",
      "Epoch 36/128\n",
      "128/128 [==============================] - 4s - loss: 0.0548 - acc: 0.9886     \n",
      "Epoch 37/128\n",
      "128/128 [==============================] - 4s - loss: 0.0498 - acc: 0.9900     \n",
      "Epoch 38/128\n",
      "128/128 [==============================] - 4s - loss: 0.0494 - acc: 0.9904     \n",
      "Epoch 39/128\n",
      "128/128 [==============================] - 4s - loss: 0.0414 - acc: 0.9922     \n",
      "Epoch 40/128\n",
      "128/128 [==============================] - 4s - loss: 0.0425 - acc: 0.9907     \n",
      "Epoch 41/128\n",
      "128/128 [==============================] - 4s - loss: 0.0409 - acc: 0.9918     \n",
      "Epoch 42/128\n",
      "128/128 [==============================] - 4s - loss: 0.0381 - acc: 0.9918     \n",
      "Epoch 43/128\n",
      "128/128 [==============================] - 4s - loss: 0.0356 - acc: 0.9928     \n",
      "Epoch 44/128\n",
      "128/128 [==============================] - 4s - loss: 0.0335 - acc: 0.9919     \n",
      "Epoch 45/128\n",
      "128/128 [==============================] - 4s - loss: 0.0343 - acc: 0.9935     \n",
      "Epoch 46/128\n",
      "128/128 [==============================] - 4s - loss: 0.0308 - acc: 0.9946     \n",
      "Epoch 47/128\n",
      "128/128 [==============================] - 4s - loss: 0.0312 - acc: 0.9946     \n",
      "Epoch 48/128\n",
      "128/128 [==============================] - 4s - loss: 0.0300 - acc: 0.9941     \n",
      "Epoch 49/128\n",
      "128/128 [==============================] - 4s - loss: 0.0276 - acc: 0.9947     \n",
      "Epoch 50/128\n",
      "128/128 [==============================] - 4s - loss: 0.0243 - acc: 0.9946     \n",
      "Epoch 51/128\n",
      "128/128 [==============================] - 4s - loss: 0.0255 - acc: 0.9936     \n",
      "Epoch 52/128\n",
      "128/128 [==============================] - 4s - loss: 0.0235 - acc: 0.9971     \n",
      "Epoch 53/128\n",
      "128/128 [==============================] - 4s - loss: 0.0249 - acc: 0.9953     \n",
      "Epoch 54/128\n",
      "128/128 [==============================] - 4s - loss: 0.0228 - acc: 0.9958     \n",
      "Epoch 55/128\n",
      "128/128 [==============================] - 4s - loss: 0.0193 - acc: 0.9963     \n",
      "Epoch 56/128\n",
      "128/128 [==============================] - 4s - loss: 0.0215 - acc: 0.9962     \n",
      "Epoch 57/128\n",
      "128/128 [==============================] - 4s - loss: 0.0203 - acc: 0.9962     \n",
      "Epoch 58/128\n",
      "128/128 [==============================] - 4s - loss: 0.0277 - acc: 0.9942     \n",
      "Epoch 59/128\n",
      "128/128 [==============================] - 4s - loss: 0.0208 - acc: 0.9965     \n",
      "Epoch 60/128\n",
      "128/128 [==============================] - 4s - loss: 0.0187 - acc: 0.9974     \n",
      "Epoch 61/128\n",
      "128/128 [==============================] - 4s - loss: 0.0161 - acc: 0.9972     \n",
      "Epoch 62/128\n",
      "128/128 [==============================] - 4s - loss: 0.0172 - acc: 0.9964     \n",
      "Epoch 63/128\n",
      "128/128 [==============================] - 4s - loss: 0.0160 - acc: 0.9972     \n",
      "Epoch 64/128\n",
      "128/128 [==============================] - 4s - loss: 0.0169 - acc: 0.9969     \n",
      "Epoch 65/128\n",
      "128/128 [==============================] - 4s - loss: 0.0160 - acc: 0.9977     \n",
      "Epoch 66/128\n",
      "128/128 [==============================] - 4s - loss: 0.0134 - acc: 0.9981     \n",
      "Epoch 67/128\n",
      "128/128 [==============================] - 4s - loss: 0.0160 - acc: 0.9976     \n",
      "Epoch 68/128\n",
      "128/128 [==============================] - 4s - loss: 0.0141 - acc: 0.9985     \n",
      "Epoch 69/128\n",
      "128/128 [==============================] - 4s - loss: 0.0147 - acc: 0.9976     \n",
      "Epoch 70/128\n",
      "128/128 [==============================] - 4s - loss: 0.0140 - acc: 0.9982     \n",
      "Epoch 71/128\n",
      "128/128 [==============================] - 4s - loss: 0.0131 - acc: 0.9980     \n",
      "Epoch 72/128\n",
      "128/128 [==============================] - 4s - loss: 0.0109 - acc: 0.9991     \n",
      "Epoch 73/128\n",
      "128/128 [==============================] - 4s - loss: 0.0121 - acc: 0.9991     \n",
      "Epoch 74/128\n",
      "128/128 [==============================] - 4s - loss: 0.0116 - acc: 0.9988     \n",
      "Epoch 75/128\n",
      "128/128 [==============================] - 4s - loss: 0.0122 - acc: 0.9985     \n",
      "Epoch 76/128\n",
      "128/128 [==============================] - 4s - loss: 0.0123 - acc: 0.9983     \n",
      "Epoch 77/128\n",
      "128/128 [==============================] - 4s - loss: 0.0098 - acc: 0.9982     \n",
      "Epoch 78/128\n",
      "128/128 [==============================] - 4s - loss: 0.0100 - acc: 0.9988     \n",
      "Epoch 79/128\n",
      "128/128 [==============================] - 4s - loss: 0.0096 - acc: 0.9990     \n",
      "Epoch 80/128\n",
      "128/128 [==============================] - 4s - loss: 0.0099 - acc: 0.9991     \n",
      "Epoch 81/128\n",
      "128/128 [==============================] - 4s - loss: 0.0088 - acc: 0.9992     \n",
      "Epoch 82/128\n",
      "128/128 [==============================] - 4s - loss: 0.0087 - acc: 0.9988     \n",
      "Epoch 83/128\n",
      "128/128 [==============================] - 4s - loss: 0.0071 - acc: 0.9994     \n",
      "Epoch 84/128\n",
      "128/128 [==============================] - 4s - loss: 0.0077 - acc: 0.9991     \n",
      "Epoch 85/128\n",
      "128/128 [==============================] - 4s - loss: 0.0077 - acc: 0.9992     \n",
      "Epoch 86/128\n",
      "128/128 [==============================] - 4s - loss: 0.0070 - acc: 0.9992     \n",
      "Epoch 87/128\n",
      "128/128 [==============================] - 4s - loss: 0.0066 - acc: 0.9999     \n",
      "Epoch 88/128\n",
      "128/128 [==============================] - 4s - loss: 0.0054 - acc: 0.9999     \n",
      "Epoch 89/128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 4s - loss: 0.0063 - acc: 0.9996     \n",
      "Epoch 90/128\n",
      " 22/128 [====>.........................] - ETA: 3s - loss: 0.0058 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-30646b74624a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[1;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator(train_data), 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.round(model.predict(train_data[0][2])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, None, 61)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, None, 256)         194560    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_26 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 588,800\n",
      "Trainable params: 588,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer2 = Input((None, input_size))\n",
    "x2 = Bidirectional(LSTM(128, return_sequences=True, weights=model.layers[1].get_weights()))(input_layer2)\n",
    "x2 = Dropout(0.5)(x2)\n",
    "x2 = Bidirectional(LSTM(128, return_sequences=False, weights=model.layers[3].get_weights()))(x2)\n",
    "output_layer2 = Dropout(0.5)(x2)\n",
    "model2 = Model(input_layer2, output_layer2)\n",
    "model2.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f15e720d160>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAHBgAAAA9CAYAAAAT+v9xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15e725b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(100, 100))\n",
    "skimage.io.imshow(model2.predict(train_data[0][6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f15e39f77f0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAAEYCAYAAADRUpMPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuYZWddJ/rvr6rTHULuF5omCSSQzDjgPAK2XI4yZg63\nwKjxwiWih+DARJQ8xzMe5xCHeQAB5wTP4IgjMqcHMgRUEmRkaDEY7uMZFEwDIiaKaUIgHUJCLgSS\ndPpW7/mjdrDod3d3paug1qr6fJ6nn97rt9eu9e61121/6613VWstAAAAAADwQM2sdAMAAAAAABgn\nATMAAAAAAIdFwAwAAAAAwGERMAMAAAAAcFgEzAAAAAAAHBYBMwAAAAAAh0XADAAAAADAYREwAwAA\nAABwWATMAAAAAAAclnUr3YADedCxJ7RjH/Kwb6uddswR3Xx7p2TkX79vb1c7Ofd2tbZ3T1ero4/v\nanvabFfb11pXOzL9cvfc8pWutv6UjX1bjjiyq2Wu/3l37+vf77qZ6mrXf/WbXe17Tj22q92xs1/G\nKev69dJm+3U/N9NvPjfddV9X27Trtq5Ws/37mD3upK6WmX7dp811pS/f3ddO23tnV7v7mId0tTvv\n7d/vI47f0C/2zlu6Wh13ct++aap/v21KbU//NvKNXf1nNO0z7yvJUUf06++I2tfPONfX2j3f6Jcx\nZf+4fVf/4447st825r5yQ9+WBz+oq9191Cl9W9Lvb8e2flubtm3cuKvfdk9fv7t/7YP6/aPddWtX\nmznqmH6+I/r3kb39imk77+5qd63v1+nx66ZsCFPeW5LsW9dvq7v2TtlHbuuPgWfu7t/fhlNP62rf\n3Nd/nsfs7Y8xu47s1+GGuSnreveUz262X8audUd1tbt399vqSa1fr+2ofr3WN2/vavfd/vWuduTp\np09p3/q+NuUYPe2YNTdl75zd06+D3bf1n8f6k/v94Su7+mWc8uC+fbNTDgr7btnR1WbW9T/v3mP7\n89TRs/12dcvOft986Pr+M5qbco6re/t1P/Vzu2fKsXz9cX375nZ2tb3rH9zVdn/huq42+8izutqG\nTNnnql+pd+7q55t2DJxm55SD/oP39tvzng39vvX1+/pz10OmnL8z059r7prrj4tfuP6mrnbWI/vj\nwVHrp5zP+s0g9+7pt4Ov3NF/Rkdu6NfVmf1hNtd/o1/I6Xv6fXrd8f021DYc3dXmprR575Tihp39\n9rf3wSd2td3bF7ldtSnHxGnXOlPOy7tn+v182vXAtOPk1GudY6dcV1fflq/d07d509H9a9td/fXe\n1zec0NWOXt9/5uvu6T/Ldkx/XTgz5dy6767+tbNH9Z/57g39hrV+yn4+bR2sm3aRNcW0M/XMlGPd\n5+/u199ZD+mPV7NTtoNp55479vZtPnHD4q49p721e6dcR6yfcu2+rvp95vO33NPVzji5f2+79vXL\nOOaer/WNOeGhXWnK7puZfVOOf1OO2dP2t91z/Xzr772jX+7R/b7/jV39ZzRtv3zwvn69ZH1/nbP3\nazd3tT33TLluSvKgRzyiq9WU7eP2ff32dtJsv752fqX/3jp7+qO62tyUT2BD+vVwx5TD3YOnfDeZ\n+Vp/bXLEcf15fm7KtfqUTXXqd6cTH9Qfd2amXFtvv71f18cd1a+/Uzb062Durn6bmdnQX/+0B/fn\nqUy5Rr1lpj9mPXSmb1/b3R8Xb1/fH3tvm/I9/Xs29t9h7tzVv7dp58eTd/fvd+64/voxt/fb1dyJ\nD+tqO/dOOe/t65d79Pp+G9ow5aJ32ms3TPsevLu/Ntmzvl/30667Tlnfb0P3tH57Oeq+/lqipm0H\n997VN++o/rM84pv9+Xbvzv7zvfv4TV3t2Lv77xt7Tujnm7YfnbKvzwfmdvXb3+xJ/XH73imr/ktT\nvp/uvPm621pr3/oCNHPsaS17px8D14K28/arWmvnrnQ7FmuwAfOxD3lYfuYNl39b7f8+pz8Q3T7X\nhyt//Pf9DvcvZ/66q+29tf8yNfO//GRXu7X1F0Vfv6/fQ75ntj8x3PSGV3e103/hl7rano3f07fl\n3v5A9Od39SepEx/UH8TO/w//o6t95DVP62rv/Fx/gPn5h/RB6r5j+4POzgf14erF7//7rvaq69/a\n1dYf219QHfsjL+xqc0f2B/fa3R+IXvY/+xPD67/+rq728af06/6PPtuf9N78I2d2td1/9FtdbcOz\nfq6rZUrw3qaEgHvX919+br23P5B/4Av9dnXCkf1nvmFdf+H/fQ/tl7Fppl9/Mzv7k9meq9/f1db9\n4E91td/7Yn9ifeZZ/QX4zle9pG/Lk7+3q/3591/Y1aYFpue2v+1qbUpw+b9v77fdN57+xa429339\ncXvf+367qx35+HO62p5N/ftY97Xt/Xx/8+dd7U8efl5XO++U/jOqKRc/SfKNE/oL/+139uvhZZdu\n62rvuPF3u9qjXvsbXe1jd/cXQD982591tRvOekZXe+TOKev6pj6ImTmmv3j6+1M2d7WPf7n/ov7C\n+/r1umfzj3e1df/j7V3t85e+p6s9+o39577v+FO72syUQGTuQf0Xop3p99djv9Zvvzu2/Keudtq/\nellX+7Xr+uPiS5/QB4HHbugvwL/5W7/S1Y48qf/C9pn/9Ze72g+d0F9AvvGaflv75Yf3x5P7Nj66\nq63b9t+72rTP7YhP/GFX+4tHPLtv372f7Wq3nvbErvbl5/5IVzvxD7Z2tTNmp/ziYsovW9/9xX69\nPPvs/hg4zbVf6/frH7il37e+cnZ//n7v3/VBzEUn98FENvTn2/ff2x8Xf/Jn/m1Xe9MVl3S179/U\nn1d2TjlGf+bmfv392rv6a7F//Kh+XV32lH7b/emP9l/sfuum/9rVHvKjP9HVdp39lK42LUC7Y2d/\nbfeIz/23rnbXDzyvq13/4/02efw7/7irnb3nxq427bgx7RrwhiP7MOmUo/prjo/v6H8BeMWn+gDn\nv5zbbwd3ruvb8p//sn/txU/qf2G/7wP99d57Hnl+V3vKw/tzyimfeEdX23POi7raUbf115nfuPIP\nutrRj3tSV/vyI5/a1R6+rj/f3lb9Nn7ihilB5ZSwdueUQOOoT7+3q/3zj/fr730XPbmrHb27P+dN\n2zZ+75b+vPDTZ/ffX/Yc0R8PpoXnfz3l2PSI4/pr2eNn+gTxh9/YX29c9q/6Y/EX7uyX8ZRP9tcl\n9dyLu9qeKWHX0Xf31/NtyjX53JSw5qad/Wd56mff3f+8H+y35w9c339G076bPemuq/uf94jHdbXb\nfvfXutpXt/XXlEnyT//zm7vatO3jD77ehz0vOK5fX3/7ytd0teP+0xVdbdox/4yZPni64sv957T5\nYVN+Qfy7/TXHxmf/i3653/vMrnbHlO/k77+uvz77mX/a73NH7u1D/x/7/f4Y86OP6zOInz9jSkB/\nVX8c23DmP+5qe5/Qf5+a+ejbutpvHtkfs/6vY/+uq+35ct/mtz3sOV3tv17Vz/c/f+n7utq7b+jf\n2507+9rPfen3u9rOf/Gvu1q9/dVd7d4XvKqrffar/XXDl6eE4j/0iH4fftTx/S9gd3yzb/OZs1M6\nUN34ua5208N/qKu97/N9xvTS0/o2f3Jfv708/to+l5h9cn+9MrftfV1tx2P7a46H/X9butrtn+23\njT/7iVd3tXM//saudvNP/buu9oHt/fv9hW98oKvds70/Ph3zov6a8jN39iebX3zrX/bzve5ZX/q2\nwr5dOeKf9Otqrdj96bcsskfjMAw2YAYAAAAA1qaa9pdeDJKAGQAAAAAYkBIwj4iAGQAAAAAYjhIw\nj4mAGQAAAAAYjEpSswLmsRAwAwAAAADDUZUZPZhHQ8AMAAAAAAyKITLGQ8AMAAAAAAyHMZhHRcAM\nAAAAAAxGJamZmZVuBoskYAYAAAAABkQP5jERMAMAAAAAw2GIjFERMAMAAAAAgyJgHg8BMwAAAAAw\nHFWpWQHzWAiYAQAAAIDBmL/Jn4B5LATMAAAAAMBwGIN5VATMAAAAAMCAVGYEzKMhYAYAAAAAhqMM\nkTEmAmYAAAAAYDAqhsgYEwEzAAAAADAoAubxEDADAAAAAMPhJn+jsqSAuapOTHJFkjOS3JDkea21\nOw8w77FJrk3y31trFy1luQAAAADAaiVgHpOl9mC+OMmHW2uXVNXFk+mXH2De1yb5syUuDwAAAABY\nxaoqM0esX+lmsEhLDZjPS3LO5PFlST6WKQFzVX1/ko1J/jTJ5iUuEwAAAABYrQyRMSpLDZg3ttZu\nnjz+auZD5G9TVTNJ3pDkZ5M87WA/rKouTHJhkhxzyqYlNg0AAAAAGCMB83gcMmCuqg8leeiUp16x\ncKK11qqqTZnvF5Nc2VrbUVUHXVZrbUuSLUmy8azHTPtZAAAAAMAqNzNz8ByR4ThkwNxaO2Cv46q6\npao2tdZurqpNSW6dMtuTkzylqn4xydFJ1lfV3a21iw+71QAAAADAqlRVKQHzaCx1iIytSS5Icsnk\n//fuP0Nr7Wfuf1xVL0qyWbgMAAAAABzIoUZCYDhmlvj6S5I8vaquy/z4ypckSVVtrqq3LLVxAAAA\nAMDaMzNTa/bfYlTVuVX1+araXlVdZ96q2lBVV0ye/2RVnbHf8w+vqrur6leW+lktqQdza+32JE+d\nUt+W5CVT6m9L8ralLBMAAAAAWMUqhsg4iKqaTfKmJE9PsiPJ1VW1tbV27YLZXpzkztbaWVV1fpLX\nJ3n+gud/M8n7l6M9Sx0iAwAAAABg2VQEzIfwhCTbW2vXJ0lVXZ7kvCQLA+bzkrx68vjdSX6nqqq1\n1qrqx5N8Mck9y9EYATMAAAAAMCCVmbU9BvPJVbVtwfSW1tqWBdOnJrlxwfSOJE/c72d8a57W2t6q\nuivJSVV1X5KXZ77385KHx0gEzAAAAADAkBgi47bW2ubv0M9+dZL/2Fq7e7lupChgBgAAAAAGZY0H\nzIdyU5LTF0yfNqlNm2dHVa1LclyS2zPf0/k5VfUbSY5PMldV97XWfudwGyNgBgAAAAAGoyqZETAf\nzNVJzq6qMzMfJJ+f5AX7zbM1yQVJ/iLJc5J8pLXWkjzl/hmq6tVJ7l5KuJwImAEAAACAgamZlW7B\ncE3GVL4oyVVJZpNc2lq7pqpek2Rba21rkrcmeUdVbU9yR+ZD6O8IATMAAAAAMCjLNT7watVauzLJ\nlfvVXrng8X1JnnuIn/Hq5WiLgBkAAAAAGIyqMkTGiAiYAQAAAIBBcZO/8RAwAwAAAACDImAeDwEz\nAAAAADAclcwYg3k0BMwAAAAAwGBU9GAeEwEzAAAAADAgJWAeEQEzAAAAADAclcwImEdDwAwAAAAA\nDEoZg3k0BMwAAAAAwGDMj8G80q1gsQTMAAAAAMBwGCJjVATMAAAAAMCAVGZmdWEeCwEzAAAAADAY\npQfzqAiYAQAAAIBBKQHzaAiYAQAAAIDBqEpmBcyjIWAGAAAAAAZFwDweAmYAAAAAYDAqJWAeEQEz\nAAAAADAchsgYFQEzAAAAADAYFQHzmAiYAQAAAIDBqErWCZhHQ8AMAAAAAAyGHszjImAGAAAAAIaj\n3ORvTATMAAAAAMBgzPdgnlnpZrBIAmYAAAAAYFD0YB4PATMAAAAAMBhVAuYxETADAAAAAINRMQbz\nmAiYAQAAAIBBmS0B81gImAEAAACAwTBExrgImAEAAACAQREwj4eAGQAAAAAYjKpknYB5NATMAAAA\nAMBguMnfuAiYAQAAAIBBETCPh4AZAAAAABgMN/kbFwEzAAAAADAYFQHzmCwpYK6qE5NckeSMJDck\neV5r7c795nlskjcnOTbJviS/3lq7YinLBQAAAABWKT2YR2WpPZgvTvLh1tolVXXxZPrl+81zb5IX\nttauq6qHJflUVV3VWvv6EpcNAAAAAKwylcr6dTMr3QwWaakB83lJzpk8vizJx7JfwNxa+/sFj79S\nVbcmOSWJgBkAAAAA+DbGYB6XpQbMG1trN08efzXJxoPNXFVPSLI+yReWuFwAAAAAYBUyBvO4HDJg\nrqoPJXnolKdesXCitdaqqh3k52xK8o4kF7TW5g4wz4VJLkySY07ZdKimAQAAAACrjR7Mh1RV5yZ5\nY5LZJG9prV2y3/Mbkrw9yfcnuT3J81trN1TV05NckvlOwLuT/JvW2keW0pZDBsyttacd6LmquqWq\nNrXWbp4EyLceYL5jk/xJkle01j5xkGVtSbIlSTae9ZgDhtUAAAAAwOpUqcyWgPlAqmo2yZuSPD3J\njiRXV9XW1tq1C2Z7cZI7W2tnVdX5SV6f5PlJbkvyo5OhjL83yVVJTl1Ke5Y6RMbWJBdkPvW+IMl7\n95+hqtYneU+St7fW3r3E5QEAAAAAq9yMgPlgnpBke2vt+iSpqsszf6+8hQHzeUlePXn87iS/U1XV\nWvvMgnmuSfKgqtrQWtt1uI1ZasB8SZJ3VdWLk3wpyfOSpKo2J3lpa+0lk9o/S3JSVb1o8roXtdb+\naonLBgAAAABWmUoyu7bz5ZOratuC6S2TkR/ud2qSGxdM70jyxP1+xrfmaa3traq7kpyU+R7M9/up\nJJ9eSricLDFgbq3dnuSpU+rbkrxk8vj3kvzeUpYDAAAAAKwRlcys7TGYb2utbf5OLqCqHpP5YTOe\nsdSftdQezAAAAAAAy2a+B/OaDpgP5aYkpy+YPm1SmzbPjqpal+S4zN/sL1V1WuaHNH5ha+0LS22M\ngBkAAAAAGBRjMB/U1UnOrqozMx8kn5/kBfvNc/+98/4iyXOSfKS11qrq+CR/kuTi1trHl6MxAmYA\nAAAAYDCMwXxwkzGVL0pyVZLZJJe21q6pqtck2dZa25rkrUneUVXbk9yR+RA6SS5KclaSV1bVKye1\nZ7TWbj3c9giYAQAAAIDhqFrrYzAfUmvtyiRX7ld75YLH9yV57pTXvS7J65azLQJmAAAAAGAwKobI\nGBMBMwAAAAAwKIbIGA8BMwAAAAAwGHowj4uAGQAAAAAYjkpmjcE8GgJmAAAAAGAw9GAeFwEzAAAA\nADAoxmAeDwEzAAAAADAYldKDeUQEzAAAAADAcBiDeVQEzAAAAADAYMyPwbzSrWCxBMwAAAAAwKDM\nGiJjNATMAAAAAMBgzPdgFjCPhYAZAAAAABiOSmZnVroRLJaAGQAAAAAYjErliBkJ81gImAEAAACA\nwTBExrgImAEAAACA4TBExqgImAEAAACAwdCDeVwEzAAAAADAoMiXx0PADAAAAAAMykwkzGMhYAYA\nAAAABqOiB/OYCJgBAAAAgEGZETCPhoAZAAAAABiO0oN5TATMAAAAAMBgVMoYzCMiYAYAAAAABkUP\n5vEQMAMAAAAAg2IM5vEQMAMAAAAAgyJfHg8BMwAAAAAwGJVkxhgZoyFgBgAAAAAGRb48HgJmAAAA\nAGBQZla6ASyagBkAAAAAGIyqpHRhHg0BMwAAAAAwKDPy5dEQMAMAAAAAg6ID83gImAEAAACAwagY\ng3lMBMwAAAAAwKAYg3k8BMwAAAAAwHCUMZjHRMAMAAAAAAyKfHk8BMwAAAAAwGBU9GAeEwEzAAAA\nADAoxmAej2W5IWNVnVtVn6+q7VV18ZTnN1TVFZPnP1lVZyzHcgEAAACA1aWSzNba/beodbSEPLaq\nfnVS/3xVPXOpn9eSezBX1WySNyV5epIdSa6uqq2ttWsXzPbiJHe21s6qqvOTvD7J85e6bAAAAABg\ntanM6MF8QEvJY6vq0UnOT/KYJA9L8qGq+kettX2H257l6MH8hCTbW2vXt9Z2J7k8yXn7zXNekssm\nj9+d5KmlnzsAAAAAsL9Kag3/W4Sl5LHnJbm8tbartfbFJNsnP++wLccYzKcmuXHB9I4kTzzQPK21\nvVV1V5KTkty2cKaqujDJhUlyzCmblqFpAAAAAMCYVGup1la6GSvp5KratmB6S2tty4LppeSxpyb5\nxH6vPXUpjR3UTf4mK2pLkmw86zFreisCAAAAgDWrza10C1bSba21zSvdiMVajoD5piSnL5g+bVKb\nNs+OqlqX5Lgkty/DsgEAAACAVabWdsB8KEvJYxfz2gdkOcZgvjrJ2VV1ZlWtz/wg0Vv3m2drkgsm\nj5+T5COtre1+7gAAAADANG2+B/Na/XdoS8ljtyY5v6o2VNWZSc5O8pdL+bSW3IN5MobHRUmuSjKb\n5NLW2jVV9Zok21prW5O8Nck7qmp7kjsy/6YBAAAAAHr6ph7QUvLYyXzvSnJtkr1JXtZa27eU9izL\nGMyttSuTXLlf7ZULHt+X5LnLsSwAAAAAYBVrba2PwXxIS8ljW2u/nuTXl6stg7rJHwAAAACAMZjH\nQ8AMAAAAAAyLgHk0BMwAAAAAwIAYImNMBMwAAAAAwHC0CJhHRMAMAAAAAAxIS+YEzGMhYAYAAAAA\nBsVN/sZDwAwAAAAADIuAeTQEzAAAAADAcLQ2/49REDADAAAAAMOiB/NoCJgBAAAAgEExBvN4CJgB\nAAAAgAFpejCPiIAZAAAAABgWAfNoCJgBAAAAgOFoejCPiYAZAAAAABiMijGYx0TADAAAAAAMy5yA\neSwEzAAAAADAcLSWzO1b6VawSAJmAAAAAGBQDJExHgJmAAAAAGBA3ORvTATMAAAAAMCwCJhHQ8AM\nAAAAAAyHMZhHRcAMAAAAAAxKm9ODeSwEzAAAAADAgOjBPCYCZgAAAABgOFoEzCMiYAYAAAAABqOl\npe0TMI+FgBkAAAAAGI6WxBjMoyFgBgAAAAAGxBjMYyJgBgAAAACGo7U0AfNoCJgBAAAAgGExRMZo\nCJgBAAAAgAHRg3lMBMwAAAAAwHC0GIN5RATMAAAAAMCANENkjIiAGQAAAAAYjpa0fXowj4WAGQAA\nAAAYkGaIjBERMAMAAAAAw9EEzGMiYAYAAAAABqUZg3k0BMwAAAAAwIDowTwmAmYAAAAAYDhaBMyH\nqapOTHJFkjOS3JDkea21O6fMd0GSfzeZfF1r7bKqOirJHyZ5VJJ9Sf64tXbxoZYpYAYAAAAABqOl\nGSLj8F2c5MOttUuq6uLJ9MsXzjAJoV+VZHPm4/xPVdXWJLuS/IfW2keran2SD1fVs1pr7z/YAgXM\nAAAAAMBw6MG8FOclOWfy+LIkH8t+AXOSZyb5YGvtjiSpqg8mObe19s4kH02S1truqvp0ktMOtUAB\nMwAAAAAwHK2l7dm90q0Yq42ttZsnj7+aZOOUeU5NcuOC6R2T2rdU1fFJfjTJGw+1wGUJmKvq3MnC\nZpO8pbV2yX7P/3KSlyTZm+RrSf5la+1Ly7FsAAAAAGA1acnaHiLj5KratmB6S2tty/0TVfWhJA+d\n8rpXLJxorbWqag904VW1Lsk7k/x2a+36Q82/5IC5qmaTvCnJ0zOfdl9dVVtba9cumO0zSTa31u6t\nql9I8htJnr/UZQMAAAAAq9DaHiLjttba5gM92Vp72oGeq6pbqmpTa+3mqtqU5NYps92UfxhGI5kf\nBuNjC6a3JLmutfZbi2nscvRgfkKS7fen2VV1eebH+vhWwNxa++iC+T+R5GeXYbkAAAAAwGrTWtra\nDpiXYmuSC5JcMvn/vVPmuSrJv6+qEybTz0jyq0lSVa9LclzmR6NYlOUImKeN2fHEg8z/4iRT7zxY\nVRcmuTBJjjll0zI0DQAAAAAYm7a2h8hYikuSvKuqXpzkS0melyRVtTnJS1trL2mt3VFVr01y9eQ1\nr5nUTsv8MBt/l+TTVZUkv9Nae8vBFvhdvclfVf1sks1Jfnja85OxRLYkycazHvOAxwcBAAAAAEau\ntbR9AubD0Vq7PclTp9S3ZUGv5NbapUku3W+eHUnqgS5zOQLmm5KcvmD6tEnt21TV0zKfgP9wa23X\nMiwXAAAAAFhlWouAeUSWI2C+OsnZVXVm5oPl85O8YOEMVfW4JP9vknNba9MGlgYAAAAASNIMkTEi\nSw6YW2t7q+qizA8OPZvk0tbaNVX1miTbWmtbk/w/SY5O8oeTsTu+3Fr7saUuGwAAAABYZfRgHpVl\nGYO5tXZlkiv3q71yweOnLcdyAAAAAIDVT8A8Ht/Vm/wBAAAAABxMay1z+/atdDNYJAEzAAAAADAo\nxmAeDwEzAAAAADAcrRkiY0QEzAAAAADAoAiYx0PADAAAAAAMRmvNEBkjImAGAAAAAAZlTg/m0RAw\nAwAAAADD0QyRMSYCZgAAAABgONzkb1QEzAAAAADAYLTEGMwjImAGAAAAAIZDD+ZRETADAAAAAIMi\nYB4PATMAAAAAMBwtmTNExmgImAEAAACAwWgxRMaYCJgBAAAAgOFoSdu3b6VbwSIJmAEAAACAAWlp\nhsgYDQEzAAAAADAcrWVu996VbgWLJGAGAAAAAAajtWTOGMyjIWAGAAAAAAbEEBljImAGAAAAAIaj\nJU0P5tEQMAMAAAAAw9GStq+tdCtYJAEzAAAAADAYLc0YzCMiYAYAAAAAhqMlbU4P5rEQMAMAAAAA\ngzJniIzREDADAAAAAIPR3ORvVATMAAAAAMBwtOYmfyMiYAYAAAAABsUQGeMhYAYAAAAAhsMQGaMi\nYAYAAAAABqMlmZvTg3ksBMwAAAAAwHAYg3lUBMwAAAAAwKDMGSJjNATMAAAAAMBgtBY9mEdEwAwA\nAAAADIeAeVQEzAAAAADAgDRDZIzIzEo3AAAAAADgW1rS5tqa/bcUVXViVX2wqq6b/H/CAea7YDLP\ndVV1wZTnt1bV3yxmmXowAwAAAACD0ZLMGSLjcF2c5MOttUuq6uLJ9MsXzlBVJyZ5VZLNmV/dn6qq\nra21OyfP/2SSuxe7QAEzAAAAADAcraUZIuNwnZfknMnjy5J8LPsFzEmemeSDrbU7kqSqPpjk3CTv\nrKqjk/xykguTvGsxCxQwAwAAAACD4iZ/h21ja+3myeOvJtk4ZZ5Tk9y4YHrHpJYkr03yhiT3LnaB\nAmYAAAAAYDBaW/NDZJxcVdsWTG9prW25f6KqPpTkoVNe94qFE621VlWLXpFV9dgkj2qt/euqOmOx\nrxMwAwAAAACD0ubW9BAZt7XWNh/oydba0w70XFXdUlWbWms3V9WmJLdOme2m/MMwGklyWuaH0nhy\nks1VdUOR7kX2AAAHj0lEQVTmc+OHVNXHWmvn5CAEzAAAAADAcMy17Nu9pgPmpdia5IIkl0z+f++U\nea5K8u+r6oTJ9DOS/OpkTOY3J8mkB/P7DhUuJ8sUMFfVuUnemGQ2yVtaa5ccYL6fSvLuJD/QWts2\nbR4AAAAAYO1qiZv8Hb5Lkryrql6c5EtJnpckVbU5yUtbay9prd1RVa9NcvXkNa+5/4Z/h2PJAXNV\nzSZ5U5KnZ35A6Kuramtr7dr95jsmyS8l+eRSlwkAAAAArFLGYD5srbXbkzx1Sn1bkpcsmL40yaUH\n+Tk3JPnexSxzOXowPyHJ9tba9UlSVZcnOS/JtfvN99okr0/yb5ZhmQAAAADAqtTSBMyjsRwB86lJ\nblwwvSPJExfOUFWPT3J6a+1PquqAAXNVXZjkwiQ55pRNy9A0AAAAAGBMWkvmmoB5LL7jN/mrqpkk\nv5nkRYeat7W2JcmWJNl41mNsRQAAAACwBu0TMI/GcgTMNyU5fcH0aZPa/Y7J/HgdH6uqJHlokq1V\n9WNu9AcAAAAALNSSGCFjPJYjYL46ydlVdWbmg+Xzk7zg/idba3clOfn+6ar6WJJfES4DAAAAANPo\nwTweSw6YW2t7q+qiJFclmU1yaWvtmqp6TZJtrbWtS10GAAAAALA26ME8LssyBnNr7cokV+5Xe+UB\n5j1nOZYJAAAAAKw+renBPCbf8Zv8AQAAAAA8EHowj4eAGQAAAAAYjJamB/OICJgBAAAAgMEwBvO4\nCJgBAAAAgEERMI+HgBkAAAAAGAw3+RsXATMAAAAAMCh6MI+HgBkAAAAAGIz5MZglzGMhYAYAAAAA\nBsNN/sZFwAwAAAAADIoezOMhYAYAAAAABmP+Jn8r3QoWS8AMAAAAAAyKHszjIWAGAAAAAAajJZlb\n6UawaAJmAAAAAGBAmh7MIyJgBgAAAAAGo8UYzGMiYAYAAAAABqO1ZPechHksBMwAAAAAwGDM92AW\nMI+FgBkAAAAAGBRDZIyHgBkAAAAAGAw9mMdFwAwAAAAADIab/I1LtYH+NqCqvpbkS5PJk5PctoLN\nAb7z7OewNtjXYfWzn8PqZz+HteG7ua8/orV2yv0TVfWnk+WvVbe11s5d6UYs1mAD5oWqaltrbfNK\ntwP4zrGfw9pgX4fVz34Oq5/9HNYG+zqLNbPSDQAAAAAAYJwEzAAAAAAAHJaxBMxbVroBwHec/RzW\nBvs6rH72c1j97OewNtjXWZRRjMEMAAAAAMDwjKUHMwAAAAAAAyNgBgAAAADgsAw6YK6qc6vq81W1\nvaouXun2AMunqm6oqs9V1V9V1bZJ7cSq+mBVXTf5/4SVbieweFV1aVXdWlV/s6A2db+ueb89Ocf/\ndVU9fuVaDjwQB9jXX11VN03O639VVc9e8NyvTvb1z1fVM1em1cADUVWnV9VHq+raqrqmqn5pUnde\nh1XiIPu5czoP2GAD5qqaTfKmJM9K8ugkP11Vj17ZVgHL7J+31h7bWts8mb44yYdba2cn+fBkGhiP\ntyU5d7/agfbrZyU5e/LvwiRv/i61EVi6t6Xf15PkP07O649trV2ZJJPr9/OTPGbymt+dXOcDw7Y3\nyf/ZWnt0kicledlkf3Zeh9XjQPt54pzOAzTYgDnJE5Jsb61d31rbneTyJOetcJuA76zzklw2eXxZ\nkh9fwbYAD1Br7c+S3LFf+UD79XlJ3t7mfSLJ8VW16bvTUmApDrCvH8h5SS5vre1qrX0xyfbMX+cD\nA9Zau7m19unJ428m+dskp8Z5HVaNg+znB+KczgENOWA+NcmNC6Z35OAbOjAuLckHqupTVXXhpLax\ntXbz5PFXk2xcmaYBy+hA+7XzPKw+F03+NP7SBcNc2ddh5KrqjCSPS/LJOK/DqrTffp44p/MADTlg\nBla3H2qtPT7zf073sqr6ZwufbK21zIfQwCphv4ZV7c1JHpXksUluTvKGlW0OsByq6ugk/y3J/9Fa\n+8bC55zXYXWYsp87p/OADTlgvinJ6QumT5vUgFWgtXbT5P9bk7wn839ac8v9f0o3+f/WlWshsEwO\ntF87z8Mq0lq7pbW2r7U2l+S/5B/+ZNa+DiNVVUdkPnT6/dbaH03Kzuuwikzbz53TORxDDpivTnJ2\nVZ1ZVeszP5D41hVuE7AMqurBVXXM/Y+TPCPJ32R+H79gMtsFSd67Mi0EltGB9uutSV44uev8k5Lc\nteBPboGR2W+s1Z/I/Hk9md/Xz6+qDVV1ZuZvAPaX3+32AQ9MVVWStyb529baby54ynkdVokD7efO\n6RyOdSvdgANpre2tqouSXJVkNsmlrbVrVrhZwPLYmOQ98+ezrEvyB621P62qq5O8q6penORLSZ63\ngm0EHqCqemeSc5KcXFU7krwqySWZvl9fmeTZmb85yL1Jfu673mDgsBxgXz+nqh6b+T+XvyHJzydJ\na+2aqnpXkmszf7f6l7XW9q1Eu4EH5AeT/G9JPldVfzWp/ds4r8NqcqD9/Ked03mgan7YJAAAAAAA\neGCGPEQGAAAAAAADJmAGAAAAAOCwCJgBAAAAADgsAmYAAAAAAA6LgBkAAAAAgMMiYAYAAAAA4LAI\nmAEAAAAAOCz/P6noVO6ZA6a8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15e3a956a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "skimage.io.imshow(model2.predict(train_data[0][2]), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f15e3887780>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAAEYCAYAAADRUpMPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXvn/AdR8fTQwY4wbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15e3917c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "skimage.io.imshow(model2.predict(train_data[0][3]), aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
